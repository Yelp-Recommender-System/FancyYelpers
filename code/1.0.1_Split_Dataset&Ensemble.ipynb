{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>business_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aBWKb49Xfkv1946YN7_SIg</td>\n",
       "      <td>sSPbLBHcEMXaJfoO8zs1bA</td>\n",
       "      <td>poSV39UqEg-gpESXafS9-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazing food, drinks, service!\\n\\nWe started w...</td>\n",
       "      <td>2016-01-17 05:33:14</td>\n",
       "      <td>Angry Crab Shack</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Seafood, Cajun/Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jCHaWXgppmZjkOdpFltWGA</td>\n",
       "      <td>D5ywfFmwtJxLReqAYlDDmw</td>\n",
       "      <td>poSV39UqEg-gpESXafS9-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I couldn't be more excited to have found this ...</td>\n",
       "      <td>2016-01-30 01:13:29</td>\n",
       "      <td>Angry Crab Shack</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Seafood, Cajun/Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>CfueO6B4_WauGRQ0cq9Whg</td>\n",
       "      <td>fhwZh6_7YxWeVEuskKMTcA</td>\n",
       "      <td>poSV39UqEg-gpESXafS9-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Loved this place! \\nI came for crab legs and w...</td>\n",
       "      <td>2016-05-07 01:19:53</td>\n",
       "      <td>Angry Crab Shack</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Seafood, Cajun/Cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0           1  aBWKb49Xfkv1946YN7_SIg  sSPbLBHcEMXaJfoO8zs1bA   \n",
       "1           2  jCHaWXgppmZjkOdpFltWGA  D5ywfFmwtJxLReqAYlDDmw   \n",
       "2           5  CfueO6B4_WauGRQ0cq9Whg  fhwZh6_7YxWeVEuskKMTcA   \n",
       "\n",
       "              business_id  stars  \\\n",
       "0  poSV39UqEg-gpESXafS9-g    5.0   \n",
       "1  poSV39UqEg-gpESXafS9-g    5.0   \n",
       "2  poSV39UqEg-gpESXafS9-g    5.0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Amazing food, drinks, service!\\n\\nWe started w...  2016-01-17 05:33:14   \n",
       "1  I couldn't be more excited to have found this ...  2016-01-30 01:13:29   \n",
       "2  Loved this place! \\nI came for crab legs and w...  2016-05-07 01:19:53   \n",
       "\n",
       "      business_name     city state  \\\n",
       "0  Angry Crab Shack  Phoenix    AZ   \n",
       "1  Angry Crab Shack  Phoenix    AZ   \n",
       "2  Angry Crab Shack  Phoenix    AZ   \n",
       "\n",
       "                                          categories  \n",
       "0  Restaurants, American (New), Seafood, Cajun/Cr...  \n",
       "1  Restaurants, American (New), Seafood, Cajun/Cr...  \n",
       "2  Restaurants, American (New), Seafood, Cajun/Cr...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this data is based on the output of 1.0.0_Data_Filtering\n",
    "data = pd.read_csv('../data/filtered_reviews_in_Phonex.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(data, m, n):\n",
    "\n",
    "    '''\n",
    "    construct rating matrix from data\n",
    "    the columns of which represent business_id\n",
    "    the rows of which represent user_id\n",
    "    the values of whose elements represent the according ratings\n",
    "    @ data: filterd_reviews \n",
    "    @ m: counts of ratings for validation\n",
    "    @ n: counts of ratings for test\n",
    "    '''\n",
    "\n",
    "    # to construct sparse matrix\n",
    "    # train\n",
    "    train_user_id = []\n",
    "    train_business_id = []\n",
    "    train_stars = []\n",
    "    # validation\n",
    "    valid_user_id = []\n",
    "    valid_business_id = []\n",
    "    valid_stars = []\n",
    "    # train + validation\n",
    "    train_valid_user_id = []\n",
    "    train_valid_business_id = []\n",
    "    train_valid_stars = []\n",
    "    # test\n",
    "    test_user_id = []\n",
    "    test_business_id = []\n",
    "    test_stars = []\n",
    "    \n",
    "    user_id_lst = data['user_id'].unique().tolist() # rows of sparse matrix\n",
    "    busi_id_lst = data['business_id'].unique().tolist() # columns of sparse matrix\n",
    "\n",
    "    train_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    valid_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    train_valid_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    test_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "\n",
    "    ranking_df = data[['user_id','business_id','stars','date']].groupby(['user_id'])\n",
    "    \n",
    "    for group_name, group_df in ranking_df:\n",
    "        group_df = group_df.sort_values(by='date')\n",
    "\n",
    "        # if the len(group_df) > valid_m + test_n, split the group_df as \n",
    "        # training set : group_df.iloc[:len(group_df)-m-n, :]\n",
    "        # validation set : group_df.iloc[len(group_df)-m-n:len(group_df)-n, :]\n",
    "        # test set : group_df.iloc[len(group_df)-n:, :]\n",
    "\n",
    "        # otherwise, not split the group_df\n",
    "        # keep the group_df as training set\n",
    "\n",
    "        if len(group_df) > m+n: \n",
    "\n",
    "            training_set = group_df.iloc[:len(group_df)-m-n, :]\n",
    "            train_user_id.extend(training_set.loc[:,'user_id'].tolist()) \n",
    "            train_business_id.extend(training_set.loc[:,'business_id'].tolist())\n",
    "            train_stars.extend(training_set.loc[:,'stars'].tolist())\n",
    "\n",
    "            validation_set = group_df.iloc[len(group_df)-m-n:len(group_df)-n, :]\n",
    "            valid_user_id.extend(validation_set.loc[:,'user_id'].tolist()) \n",
    "            valid_business_id.extend(validation_set.loc[:,'business_id'].tolist())\n",
    "            valid_stars.extend(validation_set.loc[:,'stars'].tolist())\n",
    "            \n",
    "            train_validation_set = group_df.iloc[:len(group_df)-n, :]\n",
    "            train_valid_user_id.extend(train_validation_set.loc[:,'user_id'].tolist()) \n",
    "            train_valid_business_id.extend(train_validation_set.loc[:,'business_id'].tolist())\n",
    "            train_valid_stars.extend(train_validation_set.loc[:,'stars'].tolist())\n",
    "\n",
    "            testing_set = group_df.iloc[len(group_df)-n:, :]\n",
    "            test_user_id.extend(testing_set.loc[:,'user_id'].tolist()) \n",
    "            test_business_id.extend(testing_set.loc[:,'business_id'].tolist())\n",
    "            test_stars.extend(testing_set.loc[:,'stars'].tolist())\n",
    "\n",
    "        else:\n",
    "            training_set = group_df\n",
    "            train_user_id.extend(training_set.loc[:,'user_id'].tolist()) \n",
    "            train_business_id.extend(training_set.loc[:,'business_id'].tolist())\n",
    "            train_stars.extend(training_set.loc[:,'stars'].tolist())\n",
    "\n",
    "    train_df = pd.DataFrame({'user_id': train_user_id, 'business_id': train_business_id, 'stars': train_stars})\n",
    "    valid_df = pd.DataFrame({'user_id': valid_user_id, 'business_id': valid_business_id, 'stars': valid_stars})\n",
    "    train_valid_df = pd.DataFrame({'user_id': train_valid_user_id, 'business_id': train_valid_business_id, 'stars': train_valid_stars})\n",
    "    test_df = pd.DataFrame({'user_id': test_user_id, 'business_id': test_business_id, 'stars': test_stars})\n",
    "\n",
    "\n",
    "    for i in range(len(train_df)):\n",
    "        ratings = train_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(train_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(train_df.iloc[i, 1]) # business_id\n",
    "        train_sparse_matrix[row_index, column_index] = ratings\n",
    "\n",
    "    for i in range(len(valid_df)):\n",
    "        ratings = valid_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(valid_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(valid_df.iloc[i, 1]) # business_id\n",
    "        valid_sparse_matrix[row_index, column_index] = ratings\n",
    "        \n",
    "    for i in range(len(train_valid_df)):\n",
    "        ratings = train_valid_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(train_valid_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(train_valid_df.iloc[i, 1]) # business_id\n",
    "        train_valid_sparse_matrix[row_index, column_index] = ratings\n",
    "        \n",
    "    for i in range(len(test_df)):\n",
    "        ratings = test_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(test_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(test_df.iloc[i, 1]) # business_id\n",
    "        test_sparse_matrix[row_index, column_index] = ratings\n",
    "\n",
    "    # calculate sparstiy of the matrix\n",
    "    train_sparsity = 1 - np.count_nonzero(train_sparse_matrix)/ (train_sparse_matrix.shape[0] * train_sparse_matrix.shape[1])\n",
    "    valid_sparsity = 1 - np.count_nonzero(valid_sparse_matrix)/ (valid_sparse_matrix.shape[0] * valid_sparse_matrix.shape[1])\n",
    "    train_valid_sparsity = 1 - np.count_nonzero(train_valid_sparse_matrix)/ (train_valid_sparse_matrix.shape[0] * train_valid_sparse_matrix.shape[1])\n",
    "    test_sparsity = 1 - np.count_nonzero(test_sparse_matrix)/ (test_sparse_matrix.shape[0] * test_sparse_matrix.shape[1])\n",
    "\n",
    "    train_sparsity *= 100\n",
    "    valid_sparsity *=100\n",
    "    train_valid_sparse_matrix *= 100\n",
    "    test_sparsity *= 100\n",
    "\n",
    "    print (f'{len(user_id_lst)} users')\n",
    "    print (f'{len(busi_id_lst)} business')\n",
    "\n",
    "    print (f'Train_rating_matrix Sparsity: {round(train_sparsity,4)}%')\n",
    "    print (f'Valid_rating_matrix Sparsity: {round(valid_sparsity,4)}%')\n",
    "    print(f'Test_rating_matrix Sparsity:  {round(test_sparsity,4)}%')\n",
    "\n",
    "\n",
    "    return train_sparse_matrix, valid_sparse_matrix, train_valid_sparse_matrix, test_sparse_matrix, \\\n",
    "           train_df, valid_df, train_valid_df, test_df, \\\n",
    "           user_id_lst, busi_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19683 users\n",
      "1728 business\n",
      "Train_rating_matrix Sparsity: 99.4691%\n",
      "Valid_rating_matrix Sparsity: 99.9427%\n",
      "Test_rating_matrix Sparsity:  99.9427%\n"
     ]
    }
   ],
   "source": [
    "train_sparse_matrix, valid_sparse_matrix, train_valid_sparse_matrix, test_sparse_matrix, \\\n",
    "           train_df, valid_df, train_valid_df, test_df, \\\n",
    "           user_id_lst, busi_id_lst = train_valid_test_split(data=data, m=1, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/train_sparse_matrix.npy', train_sparse_matrix)\n",
    "np.save('../data/valid_sparse_matrix.npy', valid_sparse_matrix)\n",
    "np.save('../data/test_sparse_matrix.npy', test_sparse_matrix)\n",
    "np.save('../data/train_valid_sparse_matrix.npy', train_valid_sparse_matrix)\n",
    "\n",
    "train_df.to_pickle('../data/train_df.pkl')\n",
    "valid_df.to_pickle('../data/valid_df.pkl')\n",
    "test_df.to_pickle('../data/test_df.pkl')\n",
    "train_valid_df.to_pickle('../data/train_valid_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19683, 1728)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19683, 1728)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19683, 1728)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparse to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_long_format(sparse_matrix):\n",
    "\n",
    "    user_loc_lst = np.nonzero(sparse_matrix)[0]\n",
    "    busi_loc_lst = np.nonzero(sparse_matrix)[1]\n",
    "    \n",
    "    prediction = [nlp_sparse[loc] for loc in zip(user_loc_lst, busi_loc_lst)]\n",
    "    \n",
    "    user_id = [user_id_lst[i] for i in user_loc_lst]\n",
    "    busi_id = [busi_id_lst[i] for i in busi_loc_lst]\n",
    "    \n",
    "    long_format = pd.DataFrame({'user_id': user_id,\n",
    "                               'busi_id': busi_id,\n",
    "                               'prediction_ratings': prediction})\n",
    "    \n",
    "    return long_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# long format to sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_format_to_sparse(data, pre_feature):\n",
    "    '''\n",
    "    @ pre_feature: the feature represents predict_ratings\n",
    "    '''\n",
    "    test_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    for i in range(len(data)):\n",
    "        predict_col_index = data.columns.get_loc(pre_feature)\n",
    "        predict_ratings = data.iloc[i, predict_col_index]\n",
    "        row_index = user_id_lst.index(data.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(data.iloc[i, 1]) # business_id\n",
    "        \n",
    "        test_sparse_matrix[row_index, column_index] = predict_ratings\n",
    "        \n",
    "    return test_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble \n",
    "\n",
    "- Baseline model\n",
    "- SGD(funk-svd)\n",
    "- ALS(with regularization)\n",
    "- SGD(svd+bias)\n",
    "- CB\n",
    "- tf-idf cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_long_format = pd.read_csv('../data/Predictions_CB_bus.csv')\n",
    "nlp_sparse = long_format_to_sparse(nlp_long_format, 'prediction_ratings')\n",
    "nlp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_tfidf_long_format = pd.read_csv('../data/Predictions_CB_tfidf.csv')\n",
    "cb_tfidf_sparse = long_format_to_sparse(cb_tfidf_long_format, 'prediction_ratings')\n",
    "cb_tfidf_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_lsi_long_format = pd.read_csv('../data/Predictions_CB_LSI.csv')\n",
    "# cb_lsi_long_format.head()\n",
    "cb_lsi_sparse = long_format_to_sparse(cb_lsi_long_format, 'pred_lsi')\n",
    "cb_lsi_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_long_format = pd.read_csv('../data/baseline_predict_df.csv')\n",
    "baseline_long_format = baseline_long_format.loc[ : , ~baseline_long_format.columns.str.contains('Unnamed')]\n",
    "baseline_sparse = long_format_to_sparse(baseline_long_format, 'predict')\n",
    "baseline_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_long_format = pd.read_csv('../data/sgd_predict_df.csv')\n",
    "sgd_long_format = sgd_long_format.loc[ : , ~sgd_long_format.columns.str.contains('Unnamed')]\n",
    "sgd_sparse = long_format_to_sparse(sgd_long_format, 'predict')\n",
    "sgd_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.save('../data/test_prediction_CF_ALS.npy', prediction)\n",
    "\n",
    "cf_als_sparse = np.load('../data/test_prediction_CF_ALS.npy')\n",
    "rows = np.nonzero(test_sparse_matrix)[0]\n",
    "cols = np.nonzero(test_sparse_matrix)[1]\n",
    "cf_als_test = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "loc_zip = zip(rows, cols)\n",
    "for loc in loc_zip:\n",
    "    cf_als_test[loc] = cf_als_sparse[loc]\n",
    "cf_als_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_sgd_sparse = np.load('../data/test_prediction_CF_SGD.npy')\n",
    "rows = np.nonzero(test_sparse_matrix)[0]\n",
    "cols = np.nonzero(test_sparse_matrix)[1]\n",
    "cf_sgd_test = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "loc_zip = zip(rows, cols)\n",
    "for loc in loc_zip:\n",
    "    cf_sgd_test[loc] = cf_sgd_sparse[loc]\n",
    "cf_sgd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE & MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(pred, actual):\n",
    "        # Ignore nonzero terms.\n",
    "        pred = pred[actual.nonzero()].flatten()\n",
    "        actual = actual[actual.nonzero()].flatten()\n",
    "        \n",
    "        return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(pred, actual):\n",
    "        # Ignore nonzero terms.\n",
    "        pred = pred[actual.nonzero()].flatten()\n",
    "        actual = actual[actual.nonzero()].flatten()\n",
    "        \n",
    "        return mean_absolute_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7866242990130192"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_mse = get_mse(nlp_sparse, valid_sparse_matrix)\n",
    "nlp_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0084162683470375"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_mae = get_mae(nlp_sparse, valid_sparse_matrix)\n",
    "nlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7902632606937827"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_tfidf_mse = get_mse(cb_tfidf_sparse, valid_sparse_matrix)\n",
    "cb_tfidf_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.009961664148823"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_tfidf_mae = get_mae(cb_tfidf_sparse, valid_sparse_matrix)\n",
    "cb_tfidf_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7904323585257838"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_lsi_mse = get_mse(cb_lsi_sparse, valid_sparse_matrix)\n",
    "cb_lsi_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0100283174474598"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_lsi_mae = get_mae(cb_lsi_sparse, valid_sparse_matrix)\n",
    "cb_lsi_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.436931792125898"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mse = get_mse(baseline_sparse, valid_sparse_matrix)\n",
    "baseline_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584879141703012"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mae = get_mae(baseline_sparse, valid_sparse_matrix)\n",
    "baseline_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4163437783279094"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_mse = get_mse(sgd_sparse, valid_sparse_matrix)\n",
    "sgd_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420043986294402"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_mae = get_mae(sgd_sparse, valid_sparse_matrix)\n",
    "sgd_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.037692307692307"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_als_mse = get_mse(cf_als_test, valid_sparse_matrix)\n",
    "cf_als_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.914820512820513"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_als_mae = get_mae(cf_als_test, valid_sparse_matrix)\n",
    "cf_als_mae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4178860388775774"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_sgd_mse = get_mse(cf_sgd_sparse, valid_sparse_matrix)\n",
    "cf_sgd_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9477884332870176"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_sgd_mae = get_mae(cf_sgd_sparse, valid_sparse_matrix)\n",
    "cf_sgd_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp + cb_tfidf + baseline + sgd + cf_als + cf_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = 1/ nlp_mse\n",
    "cb_tfidf = 1/ cb_tfidf_mse\n",
    "cb_lsi = 1/cb_lsi_mse\n",
    "baseline = 1/ baseline_mse\n",
    "sgd = 1/ sgd_mse\n",
    "cf_als = 1/ cf_als_mse\n",
    "cf_sgd = 1/ cf_sgd_mse\n",
    "\n",
    "all_ = nlp + cb_tfidf + cb_lsi + cf_sgd+  baseline + sgd \n",
    "\n",
    "nlp = nlp/ all_\n",
    "cb_tfidf = cb_tfidf/ all_\n",
    "cb_lsi = cb_lsi/ all_\n",
    "baseline = baseline/ all_\n",
    "sgd = sgd/ all_\n",
    "cf_als = cf_als/ all_\n",
    "cf_sgd = cf_sgd/ all_\n",
    "\n",
    "\n",
    "ensemble_matrix = \\\n",
    "nlp * nlp_sparse + cb_tfidf * cb_tfidf_sparse + cb_lsi * cb_lsi_sparse + cf_als * cf_als_sparse \\\n",
    "+ cf_sgd * cf_sgd_sparse + baseline * baseline_sparse + sgd * sgd_sparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.48058483886994"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_mse = get_mse(ensemble_matrix, valid_sparse_matrix)\n",
    "ensemble_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9477884332870176"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_mae = get_mae(cf_sgd_sparse, valid_sparse_matrix)\n",
    "ensemble_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_sgd + nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_sgd = 1/ cf_sgd_mse\n",
    "# nlp = 1/ nlp_mse\n",
    "# all_ = cf_sgd + nlp\n",
    "# cf_sgd = cf_sgd/ all_\n",
    "# nlp = nlp/ all_\n",
    "\n",
    "# ensemble_matrix = nlp * nlp_sparse + cf_sgd * sgd_sparse\n",
    "# ensemble_mse = get_mse(ensemble_matrix, test_sparse_matrix)\n",
    "# ensemble_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
