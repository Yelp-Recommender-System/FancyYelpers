{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the CB models based on optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "import re\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import nltk\n",
    "# import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import scipy\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import corpora\n",
    "from gensim.similarities.docsim import Similarity\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import Utils as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text Prepocessing\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "            \n",
    "    return new_words\n",
    "\n",
    "def remove_special(words):\n",
    "    \"\"\"Remove special signs like &*\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[-,$()#+&*]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "            \n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "            \n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"  \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    myStopWords = []\n",
    "    stopwords.extend(myStopWords)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "            \n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert words to lowercase\"\"\"\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "        \n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "        \n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "        \n",
    "    return lemmas\n",
    "\n",
    "def normalize_lemmatize(words):\n",
    "    words = remove_special(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = stem_words(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words\n",
    "\n",
    "def get_processed(sample):\n",
    "    processed = pd.DataFrame(data=[],columns = ['business_id', 'text'])\n",
    "    new_texts = []\n",
    "\n",
    "    for i in range(0, len(sample)):\n",
    "        business_id = sample['business_id'].iloc[i]\n",
    "        words = nltk.word_tokenize(sample['text'].iloc[i])\n",
    "        text = ' '.join(normalize_lemmatize(words))\n",
    "        dfnew = pd.DataFrame([[business_id, text]], columns=['business_id', 'text'])\n",
    "        new_texts.append(text)\n",
    "        processed = processed.append(dfnew,ignore_index = True)\n",
    "    return processed\n",
    "\n",
    "## Similarity matrix\n",
    "\n",
    "def get_tfidf_matrix(processed):\n",
    "    '''\n",
    "    get the Tf-Idf matrix of processed texts for business reviews\n",
    "    \n",
    "    '''\n",
    "    TV = TfidfVectorizer(stop_words = \"english\")\n",
    "    processed[\"text\"] = processed[\"text\"].fillna('')\n",
    "    tfidf_matrix = TV.fit_transform((processed[\"text\"]))\n",
    "    \n",
    "    return tfidf_matrix\n",
    "\n",
    "def get_cos_sim_matrix(tfidf_matrix, n):\n",
    "    '''\n",
    "    use truncated SVD to reduce dimensions to n \n",
    "    @n: the dimensions to keep\n",
    "    '''\n",
    "    SVD = TruncatedSVD(n_components = n , random_state = 42) # 42 is the ultimate answer to everything\n",
    "    tfidf_truncated = SVD.fit_transform(tfidf_matrix)\n",
    "    cosine_sim = cosine_similarity(tfidf_truncated, tfidf_truncated)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "def get_euclidean_sim(business, n_components):\n",
    "    \n",
    "    SVD = TruncatedSVD(n_components = n_components , random_state = 42) # 42 is the ultimate answer to everything\n",
    "    bus_truncated = SVD.fit_transform(business)\n",
    "    \n",
    "    eucl_dist = euclidean_distances(bus_truncated)\n",
    "    eucl_sim = 1/np.exp(eucl_dist)\n",
    "    return eucl_sim\n",
    "    \n",
    "def get_buscosine_sim(business,n_components):\n",
    "    SVD = TruncatedSVD(n_components = n_components , random_state = 42) # 42 is the ultimate answer to everything\n",
    "    bus_truncated = SVD.fit_transform(business)\n",
    "    \n",
    "    cosine_sim = cosine_similarity(bus_truncated, bus_truncated)\n",
    "    return cosine_sim\n",
    "\n",
    "def get_mix_sim_matrix(cosine_sim, bus_cos_sim, lmbda = 0.5, ):\n",
    "    mixed_sim = np.add(cosine_sim*lmbda, bus_cos_sim*(1-lmbda)) # assume equally weighted\n",
    "\n",
    "    return mixed_sim\n",
    "\n",
    "def get_mix_sim_df(df_tfidf_sim, df_bus_sim, lmbda = 0.5):\n",
    "    df_tfidf_pivot = pd.melt(df_tfidf_sim.reset_index(), id_vars = \"index\" , value_vars = df_tfidf_sim.columns.values)\n",
    "    df_bus_pivot = pd.melt(df_bus_sim.reset_index(), id_vars = \"index\" , value_vars = df_bus_sim.columns.values)\n",
    "    \n",
    "    df_merge = pd.merge(df_tfidf_pivot, df_bus_pivot, on = [\"index\", \"variable\"])\n",
    "    df_merge[\"value\"] = (lmbda) * df_merge[\"value_x\"] + (1-lmbda) * df_merge[\"value_y\"]\n",
    "    \n",
    "    df_mixed_sim = pd.pivot(df_merge, index=\"index\", columns=\"variable\", values =\"value\")\n",
    "    return df_mixed_sim\n",
    "## Get recommendations and prediction\n",
    "def get_recommendation_cos(reviews, business_id, user_id, df_sim, k):\n",
    "    '''get the business_id_array that shows top_k greatest similarity to the specific business_id'''\n",
    "    user_bids = reviews[reviews['user_id']==user_id]['business_id'].values\n",
    "    df_user = df_sim.loc[df_sim.index.isin(user_bids), df_sim.columns == business_id]\n",
    "    df_user_topk = df_user.sort_values(df_user.columns[0], ascending = False).iloc[:k]\n",
    "    \n",
    "    return np.array(df_user_topk.index.values)\n",
    "\n",
    "\n",
    "def predict_rating(reviews, user_id, business_ids):\n",
    "    '''predict the avg of the user's rating on business in business_ids'''\n",
    "    scores = reviews.loc[(reviews.user_id == user_id) & (reviews.business_id.isin(business_ids))][\"stars\"].values\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def get_results_cos(reviews, reviews_test, business_id, user_id, df_sim, k):\n",
    "    '''\n",
    "    prediction on the business_idï¼šavg the ratings on top_k business that shows similarity to the business_id\n",
    "    actual on the business_id: the true rating \n",
    "    '''\n",
    "    actual = reviews_test.loc[(reviews_test.user_id==user_id) & (reviews_test.business_id==business_id)]['stars'].values[0]\n",
    "    business_ids = get_recommendation_cos(reviews, business_id, user_id, df_sim, k)\n",
    "    prediction = predict_rating(reviews, user_id, business_ids)\n",
    "    \n",
    "    return actual, prediction\n",
    "\n",
    "def get_review_processed(processed, reviews):\n",
    "    reviews_processed = reviews.loc[reviews.business_id.isin(processed.business_id)]\\\n",
    "                                                       .reset_index()\\\n",
    "                                                       .drop(columns=['index'])\n",
    "    return reviews_processed\n",
    "\n",
    "def CB_predict(reviews, reviews_test, df_sim, k = 5):\n",
    "    '''\n",
    "    based on test_df \n",
    "    get a dataframe with each user on each business's true ratings and prediction ratings\n",
    "    @df_sim, n*n DataFrame for business similarities\n",
    "    @k: int, top k similar businesses\n",
    "    '''\n",
    "    user_id_sample = reviews_test['user_id'].values\n",
    "    busi_id_sample = reviews_test['business_id'].values\n",
    "    \n",
    "    actual = []\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(reviews_test)):\n",
    "        try:\n",
    "            act, pred = get_results_cos(reviews, reviews_test, busi_id_sample[i], user_id_sample[i], df_sim, k)\n",
    "            actual.append(act)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "        except:\n",
    "            actual.append(np.nan)\n",
    "            predictions.append(np.nan)\n",
    "            \n",
    "    return pd.DataFrame({\"user_id\": user_id_sample,\n",
    "                         \"business_id\": busi_id_sample,\n",
    "                         \"true_ratings\": actual,\n",
    "                         \"prediction_ratings\":  predictions                        \n",
    "                        })\n",
    "\n",
    "## LSI model\n",
    "def get_lsi(processed, reviews, user_id, n_topics):\n",
    "    '''\n",
    "    get the lsi model for user_id\n",
    "    '''\n",
    "    user_bids = reviews[reviews['user_id']==user_id]['business_id'].values\n",
    "    processed_user = processed.loc[processed.business_id.isin(user_bids)]\n",
    "    documents = list(processed_user['text'].values)\n",
    "    texts = [[word for word in document.split(' ')] for document in documents]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts] \n",
    "\n",
    "    lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=n_topics)\n",
    "    \n",
    "    return lsi, dictionary, corpus\n",
    "\n",
    "def get_recommendation_lsi(processed, reviews, df_lsi, business_id, user_id, k, n_topics):\n",
    "    lsi = df_lsi[(df_lsi[\"n_topic\"] == n_topics) & (df_lsi[\"user_id\"] == user_id)][\"lsi\"][0]\n",
    "    dictionary = df_lsi[(df_lsi[\"n_topic\"] == n_topics) & (df_lsi[\"user_id\"] == user_id)][\"dictionary\"][0]\n",
    "    user_bids = reviews[reviews['user_id']==user_id]['business_id'].values\n",
    "    processed_user = processed.loc[processed.business_id.isin(user_bids)]\n",
    "    documents = list(processed_user['text'].values)\n",
    "    texts = [[word for word in document.split(' ')] for document in documents]\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts] \n",
    "    \n",
    "    doc = processed['text'].loc[processed.business_id==business_id].values[0]\n",
    "    vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "    vec_lsi = lsi[vec_bow]\n",
    "    index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "    sims = list(index[vec_lsi])\n",
    "    results = list(zip(user_bids, sims))\n",
    "    results_ordered = np.array(sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    results_topk = results_ordered[:k]\n",
    "    \n",
    "    return results_topk[:,0]\n",
    "\n",
    "def get_results_lsi(processed,reviews,reviews_test, df_lsi ,business_id,user_id,k,n_topics):\n",
    "    actual = reviews_test.loc[(reviews_test.user_id==user_id) & (reviews_test.business_id==business_id)]['stars'].values[0]\n",
    "    business_ids = get_recommendation_lsi(processed,reviews,df_lsi ,business_id,user_id,k,n_topics)\n",
    "    prediction = predict_rating(reviews, user_id, business_ids)\n",
    "    return actual, prediction\n",
    "\n",
    "def get_recommendation_lsi(processed,reviews,business_id,user_id,k,n_topics):\n",
    "    user_bids = reviews[reviews['user_id']==user_id]['business_id'].values\n",
    "    processed_user = processed.loc[processed.business_id.isin(user_bids)]\n",
    "    documents = list(processed_user['text'].values)\n",
    "    texts = [[word for word in document.split(' ')] for document in documents]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts] \n",
    "\n",
    "    lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=n_topics)\n",
    "    doc = processed['text'].loc[processed.business_id==business_id].values[0]\n",
    "    vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "    vec_lsi = lsi[vec_bow]\n",
    "    index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "    sims = list(index[vec_lsi])\n",
    "    results = list(zip(user_bids, sims))\n",
    "    results_ordered = np.array(sorted(results, key=lambda x: x[1], reverse=True))\n",
    "    results_topk = results_ordered[:k]\n",
    "    \n",
    "    return results_topk[:,0]\n",
    "\n",
    "def get_results_lsi(processed,reviews,reviews_test ,business_id,user_id,k,n_topics):\n",
    "    actual = reviews_test.loc[(reviews_test.user_id==user_id) & (reviews_test.business_id==business_id)]['stars'].values[0]\n",
    "    business_ids = get_recommendation_lsi(processed,reviews,business_id,user_id,k,n_topics)\n",
    "    prediction = predict_rating(reviews, user_id, business_ids)\n",
    "    return actual, prediction\n",
    "\n",
    "def CB_LSI_predict(df_texts_train, reviews, reviews_test, k = 5, n_topics = 100):\n",
    "    uid_sample = reviews_test['user_id'].values\n",
    "    bid_sample = reviews_test['business_id'].values\n",
    "    actual_lsi = []\n",
    "    predictions_lsi = []\n",
    "    for i in range(len(reviews_test)):\n",
    "        try:\n",
    "            act, pred = get_results_lsi(df_texts_train, reviews, reviews_test, bid_sample[i],uid_sample[i], k, n_topics)\n",
    "            predictions_lsi.append(pred)\n",
    "            actual_lsi.append(act)\n",
    "\n",
    "        except:\n",
    "            predictions_lsi.append(np.nan)\n",
    "            actual_lsi.append(np.nan)\n",
    "            \n",
    "    return pd.DataFrame({\"user_id\": uid_sample,\n",
    "                         \"business_id\": bid_sample,\n",
    "                         \"ratings\": actual_lsi,\n",
    "                         \"pred_lsi\":  predictions_lsi})\n",
    "\n",
    "def get_recommendation_cos_full(reviews, user_id, df_sim, k, busi_id_lst):\n",
    "    '''get the business_id_array that shows top_k greatest similarity to the specific business_id'''\n",
    "    \n",
    "    df_user_rating = reviews[reviews.user_id == user_id]\n",
    "#     df_sim = df_sim.loc[busi_id_lst, busi_id_lst]\n",
    "    user_bids = df_user_rating['business_id'].values\n",
    "    df_user = df_sim.loc[df_sim.index.isin(user_bids)]\n",
    "    df_user_rank = df_user.rank(ascending = False, axis = 0)\n",
    "    df_user_rank[df_user_rank <= k] = 1\n",
    "    df_user_rank[df_user_rank > k] = 0\n",
    "    df_user_rank = df_user_rank/ np.min([k, len(user_bids)])\n",
    "  \n",
    "    user_rating_matrix = np.array(df_user_rating[[\"business_id\", \"stars\"]].set_index([\"business_id\"]).loc[df_user_rank.index.values])\n",
    "    pred = user_rating_matrix.T @ np.array(df_user_rank)\n",
    "    return pred\n",
    "\n",
    "def CB_sim_fit_full_matrix(train_valid_df, df_sim, k, user_id_lst, busi_id_lst):\n",
    "    rating_pred_matrix = np.zeros((len(user_id_lst), len(busi_id_lst)))\n",
    "    for i,user_id in enumerate(user_id_lst):\n",
    "        rating_pred_matrix[i,] = get_recommendation_cos_full(train_valid_df, user_id, df_sim, k, busi_id_lst)\n",
    "    return(rating_pred_matrix)\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore zero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>RestaurantsGoodForGroups</th>\n",
       "      <th>OutdoorSeating</th>\n",
       "      <th>BusinessAcceptsCreditCards</th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>GoodForKids</th>\n",
       "      <th>...</th>\n",
       "      <th>Ambience_casual</th>\n",
       "      <th>Parking</th>\n",
       "      <th>music</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lpQziF9QCVZQRkxac1xzcw</th>\n",
       "      <td>-0.155783</td>\n",
       "      <td>-0.475781</td>\n",
       "      <td>0.426501</td>\n",
       "      <td>-0.446236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        latitude  longitude     stars  review_count  is_open  \\\n",
       "business_id                                                                    \n",
       "lpQziF9QCVZQRkxac1xzcw -0.155783  -0.475781  0.426501     -0.446236        1   \n",
       "\n",
       "                        RestaurantsGoodForGroups  OutdoorSeating  \\\n",
       "business_id                                                        \n",
       "lpQziF9QCVZQRkxac1xzcw                         1               0   \n",
       "\n",
       "                        BusinessAcceptsCreditCards  RestaurantsTakeOut  \\\n",
       "business_id                                                              \n",
       "lpQziF9QCVZQRkxac1xzcw                           1                   1   \n",
       "\n",
       "                        GoodForKids  ...  Ambience_casual  Parking  music  \\\n",
       "business_id                          ...                                    \n",
       "lpQziF9QCVZQRkxac1xzcw            0  ...                1        1      0   \n",
       "\n",
       "                        Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
       "business_id                                                            \n",
       "lpQziF9QCVZQRkxac1xzcw       1        1          1         1       1   \n",
       "\n",
       "                        Saturday  Sunday  \n",
       "business_id                               \n",
       "lpQziF9QCVZQRkxac1xzcw         1       1  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "rev_busi_Pho= pd.read_csv('../data/filtered_reviews_in_Phonex.csv', parse_dates=[\"date\"])\n",
    "\n",
    "user_id_lst = rev_busi_Pho['user_id'].unique().tolist() # rows of sparse matrix\n",
    "busi_id_lst = rev_busi_Pho['business_id'].unique().tolist() # columns of sparse matrix\n",
    "\n",
    "# train_valid_df  = pickle.load(open('../data/train_valid_df.pkl', \"rb\"))\n",
    "test_df = pickle.load(open('../data/test_df.pkl', \"rb\"))\n",
    "train_df  = pickle.load(open('../data/train_df.pkl', \"rb\"))\n",
    "valid_df = pickle.load(open('../data/valid_df.pkl', \"rb\"))\n",
    "\n",
    "train_sparse_matrix = np.load('train_sparse_matrix.npy')\n",
    "test_sparse_matrix = np.load('test_sparse_matrix.npy')\n",
    "valid_sparse_matrix = np.load('valid_sparse_matrix.npy')\n",
    "\n",
    "\n",
    "bus_df_subset = pd.read_csv(\"../data/business_subset_cleaned.csv\", index_col= \"business_id\")\n",
    "bus_df_subset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. non-NLP CB Model (CB_Bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 1728)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = 15\n",
    "similarity = \"cos\" # or \"eucl\"\n",
    "n_components1 = 10\n",
    "\n",
    "if similarity == \"cos\":\n",
    "    bus_sim = get_buscosine_sim(bus_df_subset, n_components1)\n",
    "else:\n",
    "    bus_sim = get_euclidean_sim(bus_df_subset, n_components1)\n",
    "    \n",
    "df_bus_sim  = pd.DataFrame(bus_sim, index= bus_df_subset.index.values, columns=bus_df_subset.index.values)\n",
    "df_bus_sim.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>business_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aBWKb49Xfkv1946YN7_SIg</td>\n",
       "      <td>sSPbLBHcEMXaJfoO8zs1bA</td>\n",
       "      <td>poSV39UqEg-gpESXafS9-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-01-17 05:33:14</td>\n",
       "      <td>Amazing food, drinks, service!\\n\\nWe started w...</td>\n",
       "      <td>Angry Crab Shack</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Seafood, Cajun/Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jCHaWXgppmZjkOdpFltWGA</td>\n",
       "      <td>D5ywfFmwtJxLReqAYlDDmw</td>\n",
       "      <td>poSV39UqEg-gpESXafS9-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-01-30 01:13:29</td>\n",
       "      <td>I couldn't be more excited to have found this ...</td>\n",
       "      <td>Angry Crab Shack</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Seafood, Cajun/Cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0           1  aBWKb49Xfkv1946YN7_SIg  sSPbLBHcEMXaJfoO8zs1bA   \n",
       "1           2  jCHaWXgppmZjkOdpFltWGA  D5ywfFmwtJxLReqAYlDDmw   \n",
       "\n",
       "              business_id  stars                date  \\\n",
       "0  poSV39UqEg-gpESXafS9-g    5.0 2016-01-17 05:33:14   \n",
       "1  poSV39UqEg-gpESXafS9-g    5.0 2016-01-30 01:13:29   \n",
       "\n",
       "                                                text     business_name  \\\n",
       "0  Amazing food, drinks, service!\\n\\nWe started w...  Angry Crab Shack   \n",
       "1  I couldn't be more excited to have found this ...  Angry Crab Shack   \n",
       "\n",
       "      city state                                         categories  \n",
       "0  Phoenix    AZ  Restaurants, American (New), Seafood, Cajun/Cr...  \n",
       "1  Phoenix    AZ  Restaurants, American (New), Seafood, Cajun/Cr...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_busi_Pho.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_cos_full(reviews, user_id, df_sim, k, busi_id_lst):\n",
    "    '''get the business_id_array that shows top_k greatest similarity to the specific business_id'''\n",
    "    \n",
    "    df_user_rating = reviews[reviews.user_id == user_id]\n",
    "#     df_sim = df_sim.loc[busi_id_lst, busi_id_lst]\n",
    "    user_bids = df_user_rating['business_id'].values\n",
    "    df_user = df_sim.loc[df_sim.index.isin(user_bids)]\n",
    "    df_user_rank = df_user.rank(ascending = False, axis = 0)\n",
    "    df_user_rank[df_user_rank <= k] = 1\n",
    "    df_user_rank[df_user_rank > k] = 0\n",
    "    df_user_rank = df_user_rank/ np.min([k, len(user_bids)])\n",
    "  \n",
    "    user_rating_matrix = np.array(df_user_rating[[\"business_id\", \"stars\"]].set_index([\"business_id\"]).loc[df_user_rank.index.values])\n",
    "    pred = user_rating_matrix.T @ np.array(df_user_rank)\n",
    "    return pred\n",
    "\n",
    "def CB_sim_fit_full_matrix(train_valid_df, df_sim, k, user_id_lst, busi_id_lst):\n",
    "    rating_pred_matrix = np.zeros((len(user_id_lst), len(busi_id_lst)))\n",
    "    for i,user_id in enumerate(user_id_lst):\n",
    "        rating_pred_matrix[i,] = get_recommendation_cos_full(train_valid_df, user_id, df_sim, k, busi_id_lst)\n",
    "    return(rating_pred_matrix)\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore zero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: (seconds)\n",
      "948.94\n",
      "MSE on test set: 1.7866242990130192\n"
     ]
    }
   ],
   "source": [
    "#### Generate model fit:\n",
    "t0 = time.time()\n",
    "pred_matrix = CB_sim_fit_full_matrix(train_df, df_bus_sim.loc[busi_id_lst, busi_id_lst],k1, user_id_lst, busi_id_lst)\n",
    "t1 = time.time()\n",
    "print(\"time elapsed: (seconds)\")\n",
    "print(np.round(t1 - t0,3))\n",
    "\n",
    "print(\"MSE on test set:\", get_mse(pred_matrix, valid_sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set: 1.7866242990130192\n"
     ]
    }
   ],
   "source": [
    "np.save('../data/pred_matrix.npy',     pred_matrix)\n",
    "print(\"MSE on test set:\", get_mse(pred_matrix, valid_sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19683, 1728)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CB - similarity with NLP (CB_NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-050d_XIor1NpCuWkbIVaQ</td>\n",
       "      <td>great food great coffe great servic amaz hashb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0WegMt6Cy966qlDKhu6jA</td>\n",
       "      <td>realli enjoy well place sport bar liter footst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0tgMGl7D9B10YjSN2ujLA</td>\n",
       "      <td>neighborhood bar comfort reason price fish fri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text\n",
       "0  -050d_XIor1NpCuWkbIVaQ  great food great coffe great servic amaz hashb...\n",
       "1  -0WegMt6Cy966qlDKhu6jA  realli enjoy well place sport bar liter footst...\n",
       "2  -0tgMGl7D9B10YjSN2ujLA  neighborhood bar comfort reason price fish fri..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_texts = pickle.load(open('../data/text_train_valid_df.pkl', \"rb\"))\n",
    "\n",
    "df_texts = pickle.load(open('../data/text_train_df.pkl', \"rb\"))\n",
    "\n",
    "\n",
    "df_texts.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "n_components2 = 20 #n singular values for reviews' vector space\n",
    "k2 = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-050d_XIor1NpCuWkbIVaQ</th>\n",
       "      <th>-0WegMt6Cy966qlDKhu6jA</th>\n",
       "      <th>-0tgMGl7D9B10YjSN2ujLA</th>\n",
       "      <th>-1UMR00eXtwaeh59pEiDjA</th>\n",
       "      <th>-45kMvS7h38CGaWugPY0rg</th>\n",
       "      <th>-8JaNeG3etLgOVyg2gOIiA</th>\n",
       "      <th>-9eNGMp8XiygI8t8QFuFWw</th>\n",
       "      <th>-A9sm-E6uQxWTJ_MuyOzFw</th>\n",
       "      <th>-Bdw-5H5C4AYSMGnAvmnzw</th>\n",
       "      <th>-BxWyEIQ6wypT-37MzZizQ</th>\n",
       "      <th>...</th>\n",
       "      <th>zSicVxnJHV8indit0oFuNw</th>\n",
       "      <th>zU63bs3Ofe8y1peOgOFJaA</th>\n",
       "      <th>zYZPpOqo_2YrLJLOmjlgPQ</th>\n",
       "      <th>zaBk2imYnk7rG7IdOMhRmA</th>\n",
       "      <th>zbrFk-4ejesAJD8EwcdHxg</th>\n",
       "      <th>zc1sur_MxkKkD6P8gYXQbg</th>\n",
       "      <th>zidkKI_N1OPxsiddTOQH_Q</th>\n",
       "      <th>znH36RmIAI4wcHy9WiEO5Q</th>\n",
       "      <th>zrTGcb83AsfyVTMrsCa65A</th>\n",
       "      <th>zwmps5SXn30g-f5wqg_r9A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-050d_XIor1NpCuWkbIVaQ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.580148</td>\n",
       "      <td>0.577455</td>\n",
       "      <td>0.958394</td>\n",
       "      <td>0.691951</td>\n",
       "      <td>0.557193</td>\n",
       "      <td>0.649372</td>\n",
       "      <td>0.327343</td>\n",
       "      <td>0.719355</td>\n",
       "      <td>0.641419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969567</td>\n",
       "      <td>0.569617</td>\n",
       "      <td>0.38946</td>\n",
       "      <td>0.250388</td>\n",
       "      <td>0.529521</td>\n",
       "      <td>0.988208</td>\n",
       "      <td>0.342962</td>\n",
       "      <td>0.565981</td>\n",
       "      <td>0.662767</td>\n",
       "      <td>0.516715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        -050d_XIor1NpCuWkbIVaQ  -0WegMt6Cy966qlDKhu6jA  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                     1.0                0.580148   \n",
       "\n",
       "                        -0tgMGl7D9B10YjSN2ujLA  -1UMR00eXtwaeh59pEiDjA  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.577455                0.958394   \n",
       "\n",
       "                        -45kMvS7h38CGaWugPY0rg  -8JaNeG3etLgOVyg2gOIiA  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.691951                0.557193   \n",
       "\n",
       "                        -9eNGMp8XiygI8t8QFuFWw  -A9sm-E6uQxWTJ_MuyOzFw  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.649372                0.327343   \n",
       "\n",
       "                        -Bdw-5H5C4AYSMGnAvmnzw  -BxWyEIQ6wypT-37MzZizQ  ...  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.719355                0.641419  ...   \n",
       "\n",
       "                        zSicVxnJHV8indit0oFuNw  zU63bs3Ofe8y1peOgOFJaA  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.969567                0.569617   \n",
       "\n",
       "                        zYZPpOqo_2YrLJLOmjlgPQ  zaBk2imYnk7rG7IdOMhRmA  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                 0.38946                0.250388   \n",
       "\n",
       "                        zbrFk-4ejesAJD8EwcdHxg  zc1sur_MxkKkD6P8gYXQbg  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.529521                0.988208   \n",
       "\n",
       "                        zidkKI_N1OPxsiddTOQH_Q  znH36RmIAI4wcHy9WiEO5Q  \\\n",
       "-050d_XIor1NpCuWkbIVaQ                0.342962                0.565981   \n",
       "\n",
       "                        zrTGcb83AsfyVTMrsCa65A  zwmps5SXn30g-f5wqg_r9A  \n",
       "-050d_XIor1NpCuWkbIVaQ                0.662767                0.516715  \n",
       "\n",
       "[1 rows x 1728 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = get_tfidf_matrix(df_texts)\n",
    "cosine_sim = get_cos_sim_matrix(tfidf_matrix, n_components2)\n",
    "df_tfidf_sim = pd.DataFrame(cosine_sim, index=df_texts['business_id'].values, columns=df_texts['business_id'].values)\n",
    "df_tfidf_sim.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: (seconds)\n",
      "847.714\n",
      "MSE on test set: 1.793311250579971\n"
     ]
    }
   ],
   "source": [
    "#### Generate model fit:\n",
    "t0 = time.time()\n",
    "pred_matrix_nlp = CB_sim_fit_full_matrix(train_df, df_tfidf_sim.loc[busi_id_lst, busi_id_lst],k1, user_id_lst, busi_id_lst)\n",
    "t1 = time.time()\n",
    "print(\"time elapsed: (seconds)\")\n",
    "print(np.round(t1 - t0,3))\n",
    "\n",
    "print(\"MSE on test set:\", get_mse(pred_matrix_nlp, valid_sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set: 1.793311250579971\n"
     ]
    }
   ],
   "source": [
    "np.save('../data/pred_matrix_nlp.npy',     pred_matrix_nlp)\n",
    "print(\"MSE on test set:\", get_mse(pred_matrix_nlp, valid_sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k4 = 50\n",
    "n_topics = 150\n",
    "df_texts = pickle.load(open('../data/text_train_valid_df.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: (seconds)\n",
      "11536.142\n"
     ]
    }
   ],
   "source": [
    "#### Generate model fit:\n",
    "t0 = time.time()\n",
    "df_pred_lsi = util.CB_LSI_predict(df_texts,train_valid_df, test_df, k = k4, n_topics = n_topics)\n",
    "t1 = time.time()\n",
    "print(\"time elapsed: (seconds)\")\n",
    "print(np.round(t1 - t0,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set: 1.8063738749611822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MSE on test set:\", mean_squared_error(df_pred_lsi.pred_lsi, df_pred_lsi.ratings ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>pred_lsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--2HUmLkcNHZp0xw6AMBPg</td>\n",
       "      <td>APXWKd1N-COyUdncd_FdyQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--4rAAfZnEIAKJE80aIiYg</td>\n",
       "      <td>HTaA1mo9cB1dXMwfJC6yKg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--CIuK7sUpaNzalLAlHJKA</td>\n",
       "      <td>8Zqh2jwtncA3N4fWEMTvZQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--Nnm_506G_p8MxAOQna5w</td>\n",
       "      <td>tIOjJWfu4Dqz-FIzXHRvCg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--mUBPK_NdRNVyhDVoUIUA</td>\n",
       "      <td>W7Dt3b6H_pMIHfxn49Pkzg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19495</th>\n",
       "      <td>zy7D8MZ8NwXO8uDraQby8g</td>\n",
       "      <td>frCxZS7lPhEnQRJ3UY6m7A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19496</th>\n",
       "      <td>zyebSPCZLUZHapi-dSHU5Q</td>\n",
       "      <td>wfxmuA7LbKZKVLV58EiWBw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>zz8rQaQvsZFZfAu-rPhLNw</td>\n",
       "      <td>h0bxE_VmJJvKKEEm4-NFRA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19498</th>\n",
       "      <td>zzF17hwmlFTuOa1Yagi-eg</td>\n",
       "      <td>umrDQGRNied77aVg29_fVw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19499</th>\n",
       "      <td>zzO9aMo33jA3pPv8SoYskw</td>\n",
       "      <td>pDewiJY6KCcZgLxxgxg13Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id             business_id  ratings  pred_lsi\n",
       "0      --2HUmLkcNHZp0xw6AMBPg  APXWKd1N-COyUdncd_FdyQ      5.0  4.593750\n",
       "1      --4rAAfZnEIAKJE80aIiYg  HTaA1mo9cB1dXMwfJC6yKg      1.0  2.833333\n",
       "2      --CIuK7sUpaNzalLAlHJKA  8Zqh2jwtncA3N4fWEMTvZQ      4.0  4.285714\n",
       "3      --Nnm_506G_p8MxAOQna5w  tIOjJWfu4Dqz-FIzXHRvCg      3.0  3.162791\n",
       "4      --mUBPK_NdRNVyhDVoUIUA  W7Dt3b6H_pMIHfxn49Pkzg      1.0  4.750000\n",
       "...                       ...                     ...      ...       ...\n",
       "19495  zy7D8MZ8NwXO8uDraQby8g  frCxZS7lPhEnQRJ3UY6m7A      4.0  4.600000\n",
       "19496  zyebSPCZLUZHapi-dSHU5Q  wfxmuA7LbKZKVLV58EiWBw      2.0  3.705882\n",
       "19497  zz8rQaQvsZFZfAu-rPhLNw  h0bxE_VmJJvKKEEm4-NFRA      4.0  3.666667\n",
       "19498  zzF17hwmlFTuOa1Yagi-eg  umrDQGRNied77aVg29_fVw      5.0  4.000000\n",
       "19499  zzO9aMo33jA3pPv8SoYskw  pDewiJY6KCcZgLxxgxg13Q      5.0  4.166667\n",
       "\n",
       "[19500 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/pred_matrix_nlp.npy', pred_matrix_nlp)\n",
    "# np.save('..data/pred_matrix.npy',     pred_matrix)\n",
    "# np.save('../data/pred_matrix_mixed.npy',     pred_matrix_mixed)\n",
    "# df_pred_lsi.to_csv(\"../data/Predictions_CB_LSI.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
